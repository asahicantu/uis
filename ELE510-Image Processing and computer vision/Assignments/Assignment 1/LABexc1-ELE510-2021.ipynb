{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ELE510 Image Processing with robot vision: LAB, Exercise 1, Fundamentals."
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Purpose:** *To learn some basic operations on images using Python, OpenCV and other packages. The emphasis is on the fundamentals of digital images.*\n",
    "\n",
    "The theory for this exercise can be found in chapter 1 and 2 of the text book [1]. Supplementary information can found in chapter 1, 2 and 3 in the compendium [2]. See also the following documentations for help:\n",
    "- [OpenCV](https://opencv.org/opencv-python-free-course/)\n",
    "- [numpy](https://numpy.org/doc/stable/)\n",
    "- [matplotlib](https://matplotlib.org/stable/contents.html)\n",
    "\n",
    "**IMPORTANT:** Read the text carefully before starting the work. In\n",
    "many cases it is necessary to do some preparations before you start the work\n",
    "on the computer. Read necessary theory and answer the theoretical part\n",
    "frst. The theoretical and experimental part should be solved individually.\n",
    "The notebook must be approved by the lecturer or his assistant.\n",
    "\n",
    "**Approval:**\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "The current notebook should be submitted on CANVAS as a single pdf file. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    To export the notebook in a pdf format, goes to File -> Download as -> PDF via LaTeX (.pdf).\n",
    "</div>\n",
    "\n",
    "**Note regarding the notebook**: The theoretical questions can be answered directly on the notebook using a *Markdown* cell and LaTex commands (if relevant). In alternative, you can attach a scan (or an image) of the answer directly in the cell.\n",
    "\n",
    "Possible ways to insert an image in the markdown cell:\n",
    "\n",
    "`![image name](\"image_path\")`\n",
    "\n",
    "`<img src=\"image_path\" alt=\"Alt text\" title=\"Title text\" />`\n",
    "\n",
    "\n",
    "**Under you will find parts of the solution that is already programmed.**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>You have to fill out code everywhere it is indicated with `...`</p>\n",
    "    <p>The code section under `######## a)` is answering subproblem a) etc.</p>\n",
    "</div>"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**a)** Make a list of at least 5 different applications of robot (machine) vision."
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. [Food Automation](https://blog.zivid.com/5-common-robot-applications-with-industrial-3d-vision)\r\n",
    "3D machine vision systems can be deployed in consumer industries like food automation, which involves food processing, segmentation, and packing using an automated machine. Up to 94% of food packaging operations are already using robotics.\r\n",
    "#### 2. [Depalletization/Depalletization](https://blog.zivid.com/5-common-robot-applications-with-industrial-3d-vision)\r\n",
    "The process of depalletizing is as arduous as monotonous. Using autonomous machines increases productivity by completing the tasks with high speed. This tasks have to involve different shapes, weights and materials, among the main challenges for these solutions.\r\n",
    "#### 2. [Bin Picking](https://blog.zivid.com/5-common-robot-applications-with-industrial-3d-vision)\r\n",
    "This is an automated process of detecting, classifying, picking, and placing a target object to achieve the desired result. It is one of the most common automation applications in smart factories and warehouses. 3D machine vision cameras play an essential role in increasing the accuracy of the bin-picking operation, especially for tiny objects and randomly distributed items.\r\n",
    "#### 3. [Military Drones](https://emerj.com/ai-sector-overviews/ai-drones-and-uavs-in-the-military-current-applications/)\r\n",
    "First world countries such as United States have invested significant capital to develop and give AI capabilities to war drones. Such objects are surpasing pilots vision capabilities to detect, filter and choose right targets by diminishing casualties. With the help of deep and expensive vision sensors drones can now detect potential targets from several kilometers away and save resources.\r\n",
    "#### 4. [Computer vision for Forest fire detection](https://omdena.com/blog/stop-wildfires)\r\n",
    "Artificial intelligence and agrotechnological companies are joining forces to create systems capable of creating wildfire detection systems with the help of deep learning. This way the algorithms can coordinate robots via drone surveilance and alarme systems that help send signals before a wildfire becomes a major issue, with the possibility of diminishing significal damage for the region. \r\n",
    "#### 5. [Precision Agriculture](https://www.phase1vision.com/blog/5-new-machine-vision-applications-in-precision-agriculture]) techniques are creating greater efficiencies and profitability in agriculture:\r\n",
    "1. **Field Robots** automate processes such as harvesting, planting, weeding and more. Machine vision systems are used to identify and categorize crops, providing essential visual input to automate such tasks.\r\n",
    "\r\n",
    "2. **Phenotyping** is crucial for ensuring only the best crop breeds are grown. Machine vision helps identify the best breeds by monitoring growth and identifying phenotypic traits that signify a robust genotype as the rapidly expanding human population needs greater volumes of food.\r\n",
    "\r\n",
    "3. **Grading and Sorting** helps to separate good crops from bad crops and determine which will be stable for longer shipments and which will go bad first and should be shipped to local markets. It combines deep learning techniques with robot arms.\r\n",
    "   \r\n",
    "4. **Livestock Identification**  monitors  Livestock's growth over the course of their lifetime to provide important information about their progress towards harvesting.\r\n",
    "   \r\n",
    "5. **Machine Guidance**  helps autonomous tractors and other vehicles in the agriculture industry to guide them in variable outdoor conditions for full autonomy.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**b)** What is the resolution of the tightly spaced cones in the fovea, and how is this compared to the spacing between pixels in a typical digital camera?\r\n",
    "* Cones are sensitive to the visible light. They are tighlty packed as a regular sampling array, spaced approximately at $$2.5 \\mu m$$. \r\n",
    "Such distribution is aproximately the same spacing as in the pixels on a typical camera sensor.\r\n",
    "  * Cones are specialized in three different kinds, being able to Filter and detect Red, Green and blue Respectively.\r\n",
    "* Rods are sensitive to low levels of light\r\n",
    "  * Rods exist in just a specific kind, therefore the inability to distinguis from colors in the darkness.   \r\n",
    "  "
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Eye Anatomy](Resources/Eye_Anatomy.jpg)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**c)** How much storage is needed for a one hour digital video (colour) with no compression if we assume a frame rate of 50 frames per second (fps) and that each image frame is $3840 \\times 2160$ pixels."
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Total number of seconds\r\n",
    "$$t=1hour * 60 minutes * 60 seconds = 3600 seconds$$\r\n",
    "2. Total number of frames\r\n",
    "$$f = t * 50 = 3600 * 50 = 180000$$   \r\n",
    "3. Number of channels [R, G, B] $$c = 3$$\r\n",
    "4. Image size = width * height * Number of channels\r\n",
    "$$image_{size} = 3840 * 2160 * 3 = 24883200 \\space bytes$$\r\n",
    "5. Total size\r\n",
    "$$total_{size} = image_{size} * f = 24883200 * 180000 = 4478976000000 \\space bytes \\approx 4.479 \\space Terabytes$$\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Problem 2"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this problem we use one image, `flower.jpg` (relative path: `./images/flower.jpg`).\n",
    "\n",
    "\n",
    "**a)** Import the image; let the name of the flower image be **A**. Find the following properties: height, width, channels, filesize [+]. Be aware tha opencv represents image colar channel in the order BGR (blue, green, red) instead of RGB as is more common.  Matplotlib use RGB, so if we are using matplotlib to show images they need to be converted first.\n",
    "\n",
    "**b)** Image **A** is represented as a 3D array in Python. With **A** as input we now want to extract 4 different 2D images:\n",
    "   - **R** representing the red colour component, \n",
    "   - **G** representing the green colour component,\n",
    "   - **B** representing the blue colour component, and\n",
    "   - **Gr** representing a grey level version.\n",
    "    \n",
    "The rgb components are found by using `A[:,:,k]` where `k=1,2 and 3`. The grey level image can be imported using a particular flag (`cv2.IMREAD_GRAYSCALE`), or converted from an already imported color-image to grayscale (find the cv2 function yourself in the documentation). Use `matplotlib` to display the colour image and the 3 colour components in the same figure.\n",
    "\n",
    "Describe how the different colour components contributes to different parts of the image (the petals and the background). Show the gray level image in a separate figure. Describe this image in relation to the colour components.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    The filesize can be checked in <b>bytes</b> using the following commands: \n",
    "\n",
    "```python\n",
    "import os \n",
    "filesize = os.path.getsize(my_path)\n",
    "```\n",
    "</div>\n"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import useful packages\r\n",
    "import os # useful for the filesize\r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "\r\n",
    "# Complete the parts with \"...\"\r\n",
    "\r\n",
    "########################################################\r\n",
    "######## a) \r\n",
    "# Import the image, which is located in the folder images/ (you can download it from CANVAS)\r\n",
    "A_path = ...\r\n",
    "A = cv2.imread(A_path) \r\n",
    "# Convert the image from BGR (OpenCV standard) to RGB (standard)  \r\n",
    "A = cv2.cvtColor(...)\r\n",
    "\r\n",
    "# image properties\r\n",
    "height = ...\r\n",
    "width = ...\r\n",
    "channels = ...\r\n",
    "filesize = ...\r\n",
    " \r\n",
    "print('Image Dimension    : ', A.shape) \r\n",
    "print('Image Height       : ', height)\r\n",
    "print('Image Width        : ', width)\r\n",
    "print('Number of Channels : ', channels)\r\n",
    "\r\n",
    "## The results should be:\r\n",
    "# Image Dimension    :  (667, 500, 3)\r\n",
    "# Image Height       :  667\r\n",
    "# Image Width        :  500\r\n",
    "# Number of Channels :  3\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########################################################\r\n",
    "######## b). \r\n",
    "# Extract 2D images (the various channels + grayscale)\r\n",
    "R = ...\r\n",
    "G = ...\r\n",
    "B = ...\r\n",
    "\r\n",
    "plt.figure(figsize=(20,20))\r\n",
    "plt.subplot(221)\r\n",
    "plt.imshow(A)\r\n",
    "plt.title('Color')\r\n",
    "plt.subplot(222)\r\n",
    "plt.imshow(R)\r\n",
    "plt.title('Red channel')\r\n",
    "plt.subplot(223)\r\n",
    "plt.imshow(...)\r\n",
    "plt.title('Green channel')\r\n",
    "plt.subplot(224)\r\n",
    "plt.imshow(...)\r\n",
    "plt.title('Blue channel')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Greyscale image\r\n",
    "Gr = cv2.imread(...)\r\n",
    "plt.figure(figsize=(10,10))\r\n",
    "plt.imshow(Gr, cmap='gray', vmin=0, vmax=255)\r\n",
    "plt.title('Greyscale image')\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Answer to question 2 b)** (describe): "
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2 continues\n",
    "\n",
    "**c)** The image data can be written to new files with a chosen format. Use `cv2.imwrite` and JPG. We want to study different degrees of compression by using `[cv2.IMWRITE_JPEG_QUALITY, jpg_quality]` as option in the `cv2.imwrite` function, where `cv2.IMWRITE_JPEG_QUALITY` is the quality flag, and `jpg_quality` is the selected quality for saving the image. Let `jpg_qualities` be `[10,20,30,40,50,60,70,80,90,95]` and make a graph that show the filesize in kB as a function of `jpg_qualities` for this image. When a repeated procedure is done, like in this case, it is efficient to make a script or a function for the problem. Display the compressed images for `jpg_qualities=10` and `jpg_qualities=50` (use `plt.imshow`). Study these images and discuss the degradation of the images caused by the compression.\n",
    "\n",
    "**d)** A simple way of finding objects in an image is by using thresholding. The OpenCV function `threshold`. performs simple thresholding and ouputs a logical image matrix. We want to find a logical mask identifying the flower (foreground and not the background) in our image. We can do that by combining the result from thresholding the red component and the blue component, `Fmask = Bmask or Rmask`. `Bmask` is the output from thresholding the blue component with a level of approximately (160/255) and `Rmask` is the result from thresholding the red component with level (200/255) approximately. Execute these operations and adjust the two levels for the best result. Display the final logical image `Fmask` and describe the result.\n",
    "\n"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########################################################\r\n",
    "######## c)\r\n",
    "# Image compression\r\n",
    "jpg_qualities = [10,20,30,40,50,60,70,80,90,95]\r\n",
    "size = []\r\n",
    "\r\n",
    "# write the images with a specific quality\r\n",
    "for jpg_quality in jpg_qualities:\r\n",
    "    filename = \"./images/flower{}.jpg\".format(str(jpg_quality))\r\n",
    "    cv2.imwrite(...)\r\n",
    "\r\n",
    "# Read the two images\r\n",
    "img10 = ...\r\n",
    "img50 = ...\r\n",
    "\r\n",
    "plt.figure(figsize=(20,10))\r\n",
    "plt.subplot(212)\r\n",
    "plt.plot(...) # Show the plot for the filesize in kB of the images generated\r\n",
    "plt.xlabel(\"Quality in percent\")\r\n",
    "plt.ylabel(\"Filesize in kB\")\r\n",
    "plt.subplot(221)\r\n",
    "plt.imshow(img10)\r\n",
    "plt.title(\"Quality 10%\")\r\n",
    "plt.subplot(222)\r\n",
    "plt.imshow(img50)\r\n",
    "plt.title(\"Quality 50%\")\r\n",
    "plt.show()\r\n",
    "\r\n",
    "########################################################\r\n",
    "######## d)\r\n",
    "# Thresholding: Black and White (binary) images\r\n",
    "\r\n",
    "# _, means that we are skipping the first output.  \r\n",
    "# look in OpenCV documentation to find out what the first output of threshold is\r\n",
    "_, Bmask = cv2.threshold(...)\r\n",
    "_, Rmask = cv2.threshold(...)\r\n",
    "Fmask = ...\r\n",
    "\r\n",
    "plt.figure(figsize=(10,10))\r\n",
    "plt.imshow(Fmask, cmap='gray', vmin=0, vmax=255)\r\n",
    "plt.title('Threshold image')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Problem 3\n",
    "\n",
    "Write a function that extracts a rectangular region from an input image, commonly known as cropping. Give the function the name **image2roi** (roi = region of interest). Let this function work as follows:\n",
    "\n",
    "**a)** Input parameters should be an iamge and the coordinates for the roi (fname, coords). First check if the image is colour or grey level. If it is colour a message should be printed out and the function closed (return). If it is a grey level image continue to the next step, **b)**.\n",
    "\n",
    "**b)** The size of the image is computed and the image displayed with indexes shown along the axis. Extract the sub image (region of interest) given the coordinates, display it and the function ended.\n",
    "\n"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''\r\n",
    "Function that takes in input an image and the coordinates for the ROI\r\n",
    "\r\n",
    "''' \r\n",
    "def image2roi(img, coords):\r\n",
    "    \r\n",
    "    if len(img.shape)>2:\r\n",
    "        ...\r\n",
    "    \r\n",
    "    # Plot the greyscale image and the ROI based on the coords values\r\n",
    "    ...\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##  To test your function, complete the following lines:\r\n",
    "\r\n",
    "coords = ...\r\n",
    "img = cv2.imread(...)  # use the flower image or something else you want. \r\n",
    "\r\n",
    "image2roi(..., ...)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4\n",
    "\n",
    "The representation of a digital image as a column vector is very useful in some occasions. We therefore include this here, from a practical view, using `python`. To explore this we start with a tiny test image. Let the image be\n",
    "\n",
    "\n",
    "\\begin{equation}\\label{eq1}\n",
    "    F(x,y) = \\begin{bmatrix} 1 & 2 & 3 & 4\\\\ 5 & 6 & 7 & 8\\\\\n",
    "     9 & 10 & 11 & 12\\\\ 13 & 14 & 15 & 16\\end{bmatrix},\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "To produce this image with `numpy`, use:\n",
    "\n",
    "```python\n",
    "F = np.matrix('1 2 3 4;5 6 7 8;9 10 11 12;13 14 15 16')\n",
    "```\n",
    "\n",
    "**a)** Use the `numpy` function `f = F.flatten()` What is the resulting f?\n",
    "\n",
    "**b)** Use the `numpy` function `reshape` to reconstruct the image matrix. Refer to [numpy.reshape](https://numpy.org/doc/1.18/reference/generated/numpy.reshape.html#numpy.reshape) for full documentation.\n",
    "\n",
    "**c)** What happens using the following operation `fr1 = F[:]`? \n",
    "\n",
    "**d)** Array and matrix operations are very efficient with `numpy`. \n",
    "Check how the following operation work: \n",
    "\n",
    "```python\n",
    "fr2 = F[2,:]\n",
    "fr3 = F[:,3]\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import useful packages\r\n",
    "import numpy as np\r\n",
    "from pprint import pprint\r\n",
    "\r\n",
    "F = np.matrix('1 2 3 4;5 6 7 8;9 10 11 12;13 14 15 16')\r\n",
    "print(\"F:\")\r\n",
    "pprint(F)\r\n",
    "\r\n",
    "######## a)\r\n",
    "f = ...\r\n",
    "print(\"f: \")\r\n",
    "pprint(f) \r\n",
    "\r\n",
    "######## b)\r\n",
    "F1 = np.reshape(...)\r\n",
    "print(\"F1: \")\r\n",
    "pprint(F1)\r\n",
    "\r\n",
    "######## c)\r\n",
    "fr1 = F[:]\r\n",
    "print(\"fr1: \")\r\n",
    "pprint(fr1)\r\n",
    "\r\n",
    "######## d)\r\n",
    "fr2 = ...\r\n",
    "fr3 = ...\r\n",
    "print(\"fr2: \")\r\n",
    "pprint(fr2)\r\n",
    "print(\"fr3: \")\r\n",
    "pprint(fr3)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Problem 4, answers:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n",
    "\n",
    "**d)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Delivery (dead line) on CANVAS: 05-09-2021 at 23:59\n"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Contact\n",
    "### Course teacher\n",
    "Professor Kjersti Engan, room E-431,\n",
    "E-mail: kjersti.engan@uis.no\n",
    "\n",
    "### Teaching assistant\n",
    "Tomasetti Luca, room E-401\n",
    "E-mail: luca.tomasetti@uis.no"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## References"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[1] S. Birchfeld, Image Processing and Analysis. Cengage Learning, 2016.\n",
    "\n",
    "[2] I. Austvoll, \"Machine/robot vision part I,\" University of Stavanger, 2018. Compendium, CANVAS."
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}